{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c76c99d",
   "metadata": {},
   "source": [
    "Attempt to implement a similar framework as explained in CsÃ¶rnyei et al. (2023) for SNe type II to SNe type Ia. This means, estimate the time of explosion from the peak of the light curve and not from the early-light curve as done with the fireball fitting procedure. Clearly did not finish this... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de826e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from ultranest import ReactiveNestedSampler\n",
    "from ultranest.plot import cornerplot\n",
    "from scipy.special import lambertw\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats\n",
    "import numpy\n",
    "import pdb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbff3bb",
   "metadata": {},
   "source": [
    "Load in the data, get rid of NaNs and separate the data into a list according to separate bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b0575c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn='2020jhf'\n",
    "lc_data = pd.read_csv('/Users/lalvopis/SNe_ICE/Photometry/geza_typeII/'+sn+'.csv', sep = ',')\n",
    "cnd = np.isnan(lc_data['f'])\n",
    "\n",
    "lc_data = lc_data[~cnd]\n",
    "\n",
    "bands = ['c', 'o', 'ztfg', 'ztfr']\n",
    "#bands = ['o', 'ztfg', 'ztfr']\n",
    "lcs = []\n",
    "for i in range (len(bands)):\n",
    "    lcs.append(lc_data[lc_data['band'] == bands[i]])\n",
    "    \n",
    "#print(lcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908fafb",
   "metadata": {},
   "source": [
    "Cut the relevant parts. Since the fitting function is simple, we can only use the initial rise, the first peak/plateu and the non-detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a907a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[         mjd        f     ef band\n",
      "18  58967.41     3.00   4.43    c\n",
      "26  58983.35  1414.67   8.28    c\n",
      "28  58987.43  1911.57   6.86    c\n",
      "31  58995.40  2520.67  10.39    c,          mjd        f     ef band\n",
      "16  58961.42    17.75   5.50    o\n",
      "17  58965.43    29.75   5.88    o\n",
      "19  58968.40   -17.75   5.00    o\n",
      "20  58969.40    18.25   5.00    o\n",
      "21  58971.39     4.00   7.89    o\n",
      "22  58975.39    58.50  12.25    o\n",
      "23  58977.44   191.50   8.50    o\n",
      "24  58979.43   490.50   8.75    o\n",
      "25  58981.39   911.25   7.00    o\n",
      "27  58985.40  1800.00   8.50    o\n",
      "29  58989.33  2198.75   8.50    o\n",
      "30  58993.39  2212.50   9.25    o\n",
      "32  58997.34  1969.75   9.25    o\n",
      "33  58999.32  1763.50   9.50    o,               mjd            f         ef  band\n",
      "1002  58962.23478     1.480905   3.581306  ztfg\n",
      "1004  58963.28924     0.286161   1.954573  ztfg\n",
      "1005  58963.28969    -1.007234   2.022928  ztfg\n",
      "1006  58963.31265     2.557525   3.541900  ztfg\n",
      "1007  58963.31509    -2.796298   3.323216  ztfg\n",
      "1011  58965.25530    -4.539843   3.139611  ztfg\n",
      "1013  58968.29902    -5.097944   3.107361  ztfg\n",
      "1017  58971.29757     0.009428   5.544919  ztfg\n",
      "1019  58974.20705   -21.617482  10.559565  ztfg\n",
      "1023  58977.33765   166.908995  17.243262  ztfg\n",
      "1026  58980.20862   637.649227   3.609514  ztfg\n",
      "1029  58986.22365  2113.726366   8.286546  ztfg\n",
      "1033  58991.30209  2392.347540   0.149518  ztfg\n",
      "1034  58994.23253  2568.997279  14.021031  ztfg\n",
      "1035  58997.21422  2351.736940   1.947776  ztfg,               mjd            f         ef  band\n",
      "1003  58962.27713     7.850973   4.060372  ztfr\n",
      "1008  58964.29054     0.554259   3.252987  ztfr\n",
      "1009  58964.29145     5.876892   2.844329  ztfr\n",
      "1012  58965.28943     3.142175   3.237023  ztfr\n",
      "1015  58968.37359    -5.446449   3.435749  ztfr\n",
      "1016  58971.21723    -2.835778   5.096562  ztfr\n",
      "1020  58974.25244    17.796047   7.474802  ztfr\n",
      "1022  58977.23242   126.963280  47.920248  ztfr\n",
      "1024  58978.28916   328.451884   5.989894  ztfr\n",
      "1025  58978.28962   345.004898   5.501961  ztfr\n",
      "1027  58980.25260   689.303288   3.468999  ztfr\n",
      "1030  58986.25606  2187.620407   4.751617  ztfr\n",
      "1032  58991.22861  2562.476994   6.636902  ztfr\n",
      "1036  58997.24997  2039.630647   0.145515  ztfr]\n"
     ]
    }
   ],
   "source": [
    "cut_lcs = []\n",
    "\n",
    "#2020jhf\n",
    "c_lim = [58960, 59000]\n",
    "o_lim = [58960, 59000]\n",
    "g_lim = [58960, 59000]\n",
    "r_lim = [58960, 59000]\n",
    "\n",
    "for i in range (len(lcs)):\n",
    "    if lcs[i]['band'].values[0] == 'c':\n",
    "        lim_cond = (lcs[i]['mjd'] > c_lim[0]) & (lcs[i]['mjd'] < c_lim[1])\n",
    "    if lcs[i]['band'].values[0] == 'o':\n",
    "        lim_cond = (lcs[i]['mjd'] > o_lim[0]) & (lcs[i]['mjd'] < o_lim[1])\n",
    "    elif lcs[i]['band'].values[0] == 'ztfg':\n",
    "        lim_cond = (lcs[i]['mjd'] > g_lim[0]) & (lcs[i]['mjd'] < g_lim[1])\n",
    "    else:\n",
    "        lim_cond = (lcs[i]['mjd'] > r_lim[0]) & (lcs[i]['mjd'] < r_lim[1])\n",
    "        \n",
    "    cut_lcs.append(lcs[i][lim_cond])\n",
    "    \n",
    "print(cut_lcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a7c17",
   "metadata": {},
   "source": [
    "Separate actual detections and non-detections by putting in a limit. This is a very by-hand step; I just made this to follow the prescription of the past analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c893440",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_nd = []\n",
    "photo_vls = []\n",
    "for i in range (len(cut_lcs)):\n",
    "    if len(cut_lcs[i]) > 0:\n",
    "        cond = cut_lcs[i]['mjd'] < 58975\n",
    "        lcs_nd.append(cut_lcs[i][cond].values[:,:3].astype(float))\n",
    "        photo_vls.append(cut_lcs[i][~cond].values[:,:3].astype(float))\n",
    "    else:\n",
    "        lcs_nd.append([])\n",
    "        photo_vls.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60ce48a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-6.59000000e+00,  1.19015976e-03,  1.75746924e-03]]), array([[-1.25800000e+01,  8.02259887e-03,  2.48587571e-03],\n",
      "       [-8.57000000e+00,  1.34463277e-02,  2.65762712e-03],\n",
      "       [-5.60000000e+00, -8.02259887e-03,  2.25988701e-03],\n",
      "       [-4.60000000e+00,  8.24858757e-03,  2.25988701e-03],\n",
      "       [-2.61000000e+00,  1.80790960e-03,  3.56610169e-03]]), array([[-1.17652200e+01,  5.76452515e-04,  1.39404832e-03],\n",
      "       [-1.07107600e+01,  1.11390190e-04,  7.60831251e-04],\n",
      "       [-1.07103100e+01, -3.92072973e-04,  7.87438880e-04],\n",
      "       [-1.06873500e+01,  9.95534214e-04,  1.37870901e-03],\n",
      "       [-1.06849100e+01, -1.08847831e-03,  1.29358470e-03],\n",
      "       [-8.74470000e+00, -1.76716549e-03,  1.22211521e-03],\n",
      "       [-5.70098000e+00, -1.98441003e-03,  1.20956190e-03],\n",
      "       [-2.70243000e+00,  3.66987645e-06,  2.15839804e-03],\n",
      "       [ 2.07050000e-01, -8.41475465e-03,  4.11038400e-03]]), array([[-1.17228700e+01,  3.06382201e-03,  1.58454958e-03],\n",
      "       [-9.70946000e+00,  2.16298159e-04,  1.26946980e-03],\n",
      "       [-9.70855000e+00,  2.29344191e-03,  1.10999199e-03],\n",
      "       [-8.71057000e+00,  1.22622579e-03,  1.26323965e-03],\n",
      "       [-5.62641000e+00, -2.12546277e-03,  1.34079215e-03],\n",
      "       [-2.78277000e+00, -1.10665503e-03,  1.98892028e-03],\n",
      "       [ 2.52440000e-01,  6.94486129e-03,  2.91702226e-03]])]\n"
     ]
    }
   ],
   "source": [
    "# The initial t0 guess\n",
    "t0_guess = 58974\n",
    "\n",
    "# Normalize the flux values, subtract initial t0 guess from times.\n",
    "for i in range (len(photo_vls)):\n",
    "    if len(photo_vls[i]) > 0:\n",
    "        norm_fact = max(photo_vls[i][:,1])\n",
    "        lcs_nd[i][:,2] /= norm_fact\n",
    "        lcs_nd[i][:,1] /= norm_fact\n",
    "        lcs_nd[i][:,0] -= t0_guess\n",
    "        \n",
    "        photo_vls[i][:,2] /= norm_fact\n",
    "        photo_vls[i][:,1] /= norm_fact\n",
    "        photo_vls[i][:,0] -= t0_guess\n",
    "        \n",
    "print(lcs_nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a391b4d",
   "metadata": {},
   "source": [
    "## Fitting procedure with UltraNest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31e0da",
   "metadata": {},
   "source": [
    "For ultranest one has to set up the parameters and the priors in a reasonable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f7f4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['t0', 'ac', 'ao', 'ag', 'ar', 'nc', 'no', 'ng', 'nr' ,'f']\n",
    "#parameters = ['t0', 'fmo', 'fmg', 'fmr', 'teo', 'teg', 'ter' ,'f']\n",
    "\n",
    "\n",
    "def prior_transform(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    params[0] = cube[0] * 10 + 5      # parameter for t0; t0 guess has already been subtracted from the data\n",
    "    params[1] = cube[1] * 0.6 + 4   # the scaling value\n",
    "    params[2] = cube[2] * 0.6 + 4\n",
    "    params[3] = cube[3] * 0.6 + 4\n",
    "    params[4] = cube[4] * 0.6 + 4\n",
    "    params[5] = cube[5] * 0.6 + 2           # the expoent, it should be around 2\n",
    "    params[6] = cube[6] * 0.6 + 2\n",
    "    params[7] = cube[7] * 0.6 +2\n",
    "    params[8] = cube[8] * 0.6 +2\n",
    "    params[9] = cube[9] * 3           # error inflation parameter; in case uncertainties are underestimated\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5971c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fitting function; fireball model - power law fitting\n",
    "def flux_evol(x, a, t0, n):    \n",
    "    return a * (x - t0)**n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67caf326",
   "metadata": {},
   "source": [
    "Likelihood for the Bayesian fitting: this is where the different band light curves get connected through t0 and the rise time condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb62614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params):\n",
    "    \n",
    "    t0, ac, ao, ag, ar, nc, no, ng, nr, f = params\n",
    "    alphas = [ac, ao, ag, ar] #scaling factor for each band\n",
    "    ns = [nc, no, ng, nr] #expoent for each band\n",
    "\n",
    "    # Check for the models in each band if the model light curve goes ABOVE the non-detections\n",
    "    #if yes, that is a bad model\n",
    "    for i in range (len(photo_vls)):   # I have put in here the last g_nondet for simplicity\n",
    "        try:\n",
    "            # It is enough to check this for the last non-det, if it is deep enough\n",
    "            non_dec_cond = lcs_nd[i][-1,1] < flux_evol(lcs_nd[i][-1,0], a=alphas[i], t0=t0, n=ns[i])  \n",
    "\n",
    "            if non_dec_cond:\n",
    "                return -9999\n",
    "            \n",
    "        # It can happen that we have no non-detections, then we cannot check the condition\n",
    "        #this is here to catch that\n",
    "        except (IndexError,AttributeError):  \n",
    "            pass\n",
    "\n",
    "    # if any of the above, return -9999, force the sampler away\n",
    "    # if we are still in here, do the actual loglike calculation\n",
    "    loglike = 0\n",
    "    for i in range (len(photo_vls)):\n",
    "        y_model = flux_evol(photo_vls[i][:,0], a=alphas[i], t0=t0, n=ns[i])\n",
    "    \n",
    "        sigma2 = photo_vls[i][:,2]**2 + y_model **2 * f**2    # the error inflation comes in here\n",
    "        loglike += -0.5 * np.sum((y_model - photo_vls[i][:,1])**2 / sigma2 + np.log(2*np.pi*sigma2))\n",
    "        \n",
    "        pdb.set_trace()\n",
    "\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3cf58",
   "metadata": {},
   "source": [
    "Do the fitting; this code can throw an AssertionError, if so, check if there are NaNs in the data.\n",
    "\n",
    "If no, just run the above def scripts again, and try once more; sometimes it starts from the wrong initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f489539",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> alphas\n",
      "[4.072677175187902, 4.560404468039326, 4.070090774756253, 4.56163052514792]\n",
      "ipdb> ns\n",
      "[2.307131044077833, 2.4010683688083203, 2.154539960121755, 2.2422345037758964]\n",
      "ipdb> photo_vls[i][:,0]\n",
      "array([ 9.35, 13.43, 21.4 ])\n",
      "ipdb> t0\n",
      "8.011513064783177\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/var/folders/hb/hpll1ddj15bf35zghh_jv_0w00098x/T/ipykernel_99924/772349429.py\u001b[0m(25)\u001b[0;36mlog_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     23 \u001b[0;31m    \u001b[0;31m# if we are still in here, do the actual loglike calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m    \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0my_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflux_evol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Error in loglikelihood function: returned non-finite number: [nan nan] for input u=[[0.30115131 0.12112863 0.93400745 0.11681796 0.93605088 0.51188507\n  0.66844728 0.2575666  0.40372417 0.56560131]\n [0.31278216 0.13329834 0.23363154 0.53428986 0.55814863 0.74320432\n  0.10832185 0.88049953 0.90525884 0.4619362 ]] p=[[8.01151306 4.07267718 4.56040447 4.07009077 4.56163053 2.30713104\n  2.40106837 2.15453996 2.2422345  1.69680392]\n [8.12782165 4.079979   4.14017893 4.32057392 4.33488918 2.44592259\n  2.06499311 2.52829972 2.54315531 1.38580859]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sampler \u001b[38;5;241m=\u001b[39m ReactiveNestedSampler(parameters, log_likelihood, prior_transform,\n\u001b[1;32m      2\u001b[0m     wrapped_params\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(parameters), \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#400 does the trick, but if you need sharp posteriors, might want to increase it; computationally expensive!\u001b[39;00m\n\u001b[1;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39mrun(min_num_live_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, dKL\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, min_ess\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultranest/integrator.py:1196\u001b[0m, in \u001b[0;36mReactiveNestedSampler.__init__\u001b[0;34m(self, param_names, loglike, transform, derived_param_names, wrapped_params, resume, run_num, log_dir, num_test_samples, draw_multiple, num_bootstraps, vectorized, ndraw_min, ndraw_max, storage_backend, warmstart_max_tau)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndraw_max \u001b[38;5;241m=\u001b[39m ndraw_max\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_tregion \u001b[38;5;241m=\u001b[39m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_likelihood_function(transform, loglike, num_test_samples):\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to_disk\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resume_similar \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to_disk:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultranest/integrator.py:1263\u001b[0m, in \u001b[0;36mReactiveNestedSampler._check_likelihood_function\u001b[0;34m(self, transform, loglike, num_test_samples)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlogical_and(u \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, u \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall(), (\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in transform function: u was modified!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(logl) \u001b[38;5;241m==\u001b[39m (num_test_samples,), (\n\u001b[1;32m   1262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in loglikelihood function: returned shape is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mshape(logl), (num_test_samples,)))\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(logl)\u001b[38;5;241m.\u001b[39mall(), (\n\u001b[1;32m   1264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in loglikelihood function: returned non-finite number: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m for input u=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m p=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (logl, u, p))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointstore\u001b[38;5;241m.\u001b[39mstack_empty \u001b[38;5;129;01mand\u001b[39;00m num_resume_test_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# test that last sample gives the same likelihood value\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     _, lastrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointstore\u001b[38;5;241m.\u001b[39mstack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Error in loglikelihood function: returned non-finite number: [nan nan] for input u=[[0.30115131 0.12112863 0.93400745 0.11681796 0.93605088 0.51188507\n  0.66844728 0.2575666  0.40372417 0.56560131]\n [0.31278216 0.13329834 0.23363154 0.53428986 0.55814863 0.74320432\n  0.10832185 0.88049953 0.90525884 0.4619362 ]] p=[[8.01151306 4.07267718 4.56040447 4.07009077 4.56163053 2.30713104\n  2.40106837 2.15453996 2.2422345  1.69680392]\n [8.12782165 4.079979   4.14017893 4.32057392 4.33488918 2.44592259\n  2.06499311 2.52829972 2.54315531 1.38580859]]"
     ]
    }
   ],
   "source": [
    "sampler = ReactiveNestedSampler(parameters, log_likelihood, prior_transform,\n",
    "    wrapped_params=np.full(len(parameters), False)\n",
    ")\n",
    "\n",
    "#400 does the trick, bcut if you need sharp posteriors, might want to increase it; computationally expensive!\n",
    "result = sampler.run(min_num_live_points=400, dKL=np.inf, min_ess=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c2312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
